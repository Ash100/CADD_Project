{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNhS/sQzOqJLF/9qaPLX7/Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ash100/CADD_Project/blob/main/QSAR_Model_Generation%20and%20Testing_Part_15.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# QSAR - MODEL Generation and Testing\n",
        "\n",
        "My name is **Dr. Ashfaq Ahmad** and I work in the field of Structure Biology and Bioinformatics. A step-by-step video demonstration can be found on [**Video Tutorial**](https://youtu.be/KSz0sQM13K0)\n",
        "\n",
        "These files are prepared for teaching and research purposes. If you want to use it for commercial purposes, please **contact us**.\n",
        "\n",
        "\n",
        "**Quantitative structureâ€“activity relationship (QSAR)** model(s) are generated by the users to test their compounds. We have already generated descriptors for our cmpound dataset. If you have not prepare your descriptors, please [**Prepare your dataset here**](https://youtu.be/NyAiwGwIPCM)\n",
        "\n",
        "Here we will generate a model, perform some training and optimization, and finally will use that model to predict Activity of Unknown compounds. Once you generate and train your model, you can keep it and use in future.\n",
        "\n",
        "I suggest you to read some literature from the field of your choice."
      ],
      "metadata": {
        "id": "3Wv6LnDCZkSc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "8zl_X1Ofdoj4"
      },
      "outputs": [],
      "source": [
        "#@title Install necessary libraries\n",
        "!pip install scikit-learn matplotlib seaborn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import necessary libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score"
      ],
      "metadata": {
        "cellView": "form",
        "id": "n5i6el04dxXn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "file_path = '/content/merged_descriptors.csv'  # Update this to your file path\n",
        "data = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "VuTLKNm5eDiH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows of the dataset\n",
        "print(data.head())"
      ],
      "metadata": {
        "id": "99dc6nC6eIUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Define features and target variable\n",
        "# Assume 'Activity' is the target variable and all other columns are features\n",
        "features = data.drop(columns=['SMILES', 'Activity'])  # Drop SMILES and Activity columns\n",
        "target = data['Activity']"
      ],
      "metadata": {
        "cellView": "form",
        "id": "_pZHvfOEeQFl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Handle missing values (optional, depending on your dataset)\n",
        "features = features.fillna(features.mean())\n",
        "target = target.fillna(target.mean())"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Go5-9xoBeUdM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Normalize/Scale features\n",
        "scaler = StandardScaler()\n",
        "features_scaled = scaler.fit_transform(features)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "pXrISzvpeXjq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Split the data into training and test sets (80:20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(features_scaled, target, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "vZmb7idsendN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build and train the simple QSAR models"
      ],
      "metadata": {
        "id": "RqockuFYbVKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Linear Regression\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "3V6DTLlpevSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Random Forest Regressor\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "Bc0YAT6OezqN",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Predict and evaluate the models - Linear Regression\n",
        "# Linear Regression\n",
        "try:\n",
        "    y_pred_lr = lr_model.predict(X_test)\n",
        "    lr_mse = mean_squared_error(y_test, y_pred_lr)\n",
        "    lr_r2 = r2_score(y_test, y_pred_lr)\n",
        "    print(\"\\nLinear Regression Results:\")\n",
        "    print(f\"Mean Squared Error: {lr_mse}\")\n",
        "    print(f\"R^2 Score: {lr_r2}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error in Linear Regression evaluation: {e}\")\n",
        "    lr_mse = None\n",
        "    lr_r2 = None"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Qs30gbvFiTNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Random Forest Regressor\n",
        "try:\n",
        "    y_pred_rf = rf_model.predict(X_test)\n",
        "    rf_mse = mean_squared_error(y_test, y_pred_rf)\n",
        "    rf_r2 = r2_score(y_test, y_pred_rf)\n",
        "    print(\"\\nRandom Forest Regressor Results:\")\n",
        "    print(f\"Mean Squared Error: {rf_mse}\")\n",
        "    print(f\"R^2 Score: {rf_r2}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error in Random Forest evaluation: {e}\")\n",
        "    rf_mse = None\n",
        "    rf_r2 = None"
      ],
      "metadata": {
        "cellView": "form",
        "id": "7uK4kaaYiZz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Save performance metrics to CSV\n",
        "metrics_data = {\n",
        "    'Model': ['Linear Regression', 'Random Forest'],\n",
        "    'Mean Squared Error': [lr_mse, rf_mse],\n",
        "    'R^2 Score': [lr_r2, rf_r2]\n",
        "}\n",
        "\n",
        "metrics_df = pd.DataFrame(metrics_data)\n",
        "metrics_df.to_csv('/content/model_performance_metrics.csv', index=False)\n",
        "print(\"Model performance metrics saved to /content/model_performance_metrics.csv\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "V54xAxHViBxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title save output result file in CSV\n",
        "output_file_path = '/content/qsar_results.csv'\n",
        "results = pd.DataFrame({\n",
        "    'SMILES': data['SMILES'],\n",
        "    'Actual Activity': target,\n",
        "    'Predicted Activity (LR)': lr_model.predict(features_scaled) if lr_mse is not None else np.nan,\n",
        "    'Predicted Activity (RF)': rf_model.predict(features_scaled) if rf_mse is not None else np.nan\n",
        "})\n",
        "results.to_csv(output_file_path, index=False)\n",
        "print(f\"QSAR results saved to {output_file_path}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "6-9lMGQcivlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Plot Actual vs. Predicted Activity for Linear Regression\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.scatterplot(x=y_test, y=y_pred_lr, alpha=0.7)\n",
        "plt.xlabel('Actual Activity')\n",
        "plt.ylabel('Predicted Activity (LR)')\n",
        "plt.title('Actual vs. Predicted Activity (Linear Regression)')\n",
        "\n",
        "# Add the ideal line where y = x\n",
        "min_val = min(y_test.min(), y_pred_lr.min())\n",
        "max_val = max(y_test.max(), y_pred_lr.max())\n",
        "plt.plot([min_val, max_val], [min_val, max_val], color='red', linestyle='--', label='Ideal Line')\n",
        "plt.legend()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "lVxMvRlvgKUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Plot Residuals for Linear Regression\n",
        "plt.subplot(1, 2, 2)\n",
        "residuals_lr = y_test - y_pred_lr\n",
        "sns.histplot(residuals_lr, kde=True)\n",
        "plt.xlabel('Residuals')\n",
        "plt.title('Residuals Plot (Linear Regression)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "tl5CfoXBgSwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Feature Importance Plot for Linear Regression\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': features.columns,\n",
        "    'Coefficient': lr_model.coef_\n",
        "})\n",
        "importance_df = importance_df.sort_values(by='Coefficient', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(x='Coefficient', y='Feature', data=importance_df)\n",
        "plt.title('Feature Importance (Linear Regression)')\n",
        "plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "f7ZJFvv5hbYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Feature Importance Plot for Random Forest\n",
        "importances = rf_model.feature_importances_\n",
        "feature_names = features.columns\n",
        "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
        "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.barplot(x='Importance', y='Feature', data=importance_df)\n",
        "plt.title('Feature Importance (Random Forest)')\n",
        "plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "PJTKLjHIgckX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Optimization strategies of the model**\n",
        "We can see that the MSE and R^2 is bit on a higher side- So, why not perform some optimization?"
      ],
      "metadata": {
        "id": "5MMhzkIqjCiZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import necessary libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np"
      ],
      "metadata": {
        "cellView": "form",
        "id": "8_fwvI8PjKDQ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Define different models for testing with some parameter settings\n",
        "models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Ridge Regression': Ridge(),\n",
        "    'Lasso Regression': Lasso(),\n",
        "    'Random Forest': RandomForestRegressor(),\n",
        "    'Gradient Boosting': GradientBoostingRegressor()\n",
        "}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "5KoThWHljbTt"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Hyperparameter grids\n",
        "param_grids = {\n",
        "    'Ridge Regression': {'alpha': [0.1, 1.0, 10.0, 100.0]},\n",
        "    'Lasso Regression': {'alpha': [0.1, 1.0, 10.0, 100.0]},\n",
        "    'Random Forest': {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20, 30]},\n",
        "    'Gradient Boosting': {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 0.2], 'max_depth': [3, 5, 7]}\n",
        "}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "gd2DXS8vjhoT"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Function to evaluate models\n",
        "def evaluate_model(model_name, model, X_train, X_test, y_train, y_test, param_grid=None):\n",
        "    if param_grid:\n",
        "        search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "        search.fit(X_train, y_train)\n",
        "        best_model = search.best_estimator_\n",
        "        best_params = search.best_params_\n",
        "        print(f\"Best parameters for {model_name}: {best_params}\")\n",
        "    else:\n",
        "        best_model = model\n",
        "        best_params = None\n",
        "\n",
        "    best_model.fit(X_train, y_train)\n",
        "    y_pred = best_model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\n{model_name} Results:\")\n",
        "    print(f\"Mean Squared Error: {mse}\")\n",
        "    print(f\"R^2 Score: {r2}\")\n",
        "\n",
        "    return best_model, mse, r2"
      ],
      "metadata": {
        "cellView": "form",
        "id": "FqjZLap3jnmH"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Evaluate models\n",
        "results = []\n",
        "for model_name, model in models.items():\n",
        "    param_grid = param_grids.get(model_name, None)\n",
        "    best_model, mse, r2 = evaluate_model(model_name, model, X_train, X_test, y_train, y_test, param_grid)\n",
        "    results.append({'Model': model_name, 'Mean Squared Error': mse, 'R^2 Score': r2})\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "dDkFwQKgjraG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Save performance metrics to CSV\n",
        "metrics_df = pd.DataFrame(results)\n",
        "metrics_df.to_csv('/content/model_performance_metrics.csv', index=False)\n",
        "print(\"Model performance metrics saved to /content/model_performance_metrics_advanced.csv\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "cGK7jzjjj8fR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Save or output results as needed\n",
        "output_file_path = '/content/qsar_results_advanced.csv'\n",
        "results_df = pd.DataFrame({\n",
        "    'SMILES': data['SMILES'],\n",
        "    'Actual Activity': target,\n",
        "    'Predicted Activity (Best Model)': best_model.predict(features_scaled) if 'best_model' in locals() else np.nan\n",
        "})\n",
        "results_df.to_csv(output_file_path, index=False)\n",
        "print(f\"QSAR results saved to {output_file_path}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "dUdjpmzskD-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Plot Actual vs. Predicted Activity for Best Model\n",
        "plt.figure(figsize=(14, 7))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.scatterplot(x=y_test, y=best_model.predict(X_test), alpha=0.7)\n",
        "plt.xlabel('Actual Activity')\n",
        "plt.ylabel('Predicted Activity')\n",
        "plt.title(f'Actual vs. Predicted Activity ({model_name})')\n",
        "\n",
        "# Add the ideal line where y = x\n",
        "min_val = min(y_test.min(), best_model.predict(X_test).min())\n",
        "max_val = max(y_test.max(), best_model.predict(X_test).max())\n",
        "plt.plot([min_val, max_val], [min_val, max_val], color='red', linestyle='--', label='Ideal Line')\n",
        "plt.legend()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ZtrnkVEOkKYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Residuals for Best Model\n",
        "plt.subplot(1, 2, 2)\n",
        "residuals = y_test - best_model.predict(X_test)\n",
        "sns.histplot(residuals, kde=True)\n",
        "plt.xlabel('Residuals')\n",
        "plt.title('Residuals Plot')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/best_model_plots.png')\n",
        "print(\"Best model plots saved to /content/best_model_plots.png\")"
      ],
      "metadata": {
        "id": "aRSH9cxGkVN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save the Best Model**"
      ],
      "metadata": {
        "id": "njsGDcUwknTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Evaluate models and track the best model\n",
        "best_model = None\n",
        "best_model_name = None\n",
        "best_mse = float('inf')  # Initialize to infinity for finding the minimum\n",
        "results = []\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    param_grid = param_grids.get(model_name, None)\n",
        "    model, mse, r2 = evaluate_model(model_name, model, X_train, X_test, y_train, y_test, param_grid)\n",
        "    results.append({'Model': model_name, 'Mean Squared Error': mse, 'R^2 Score': r2})\n",
        "\n",
        "    if mse < best_mse:\n",
        "        best_mse = mse\n",
        "        best_model = model\n",
        "        best_model_name = model_name"
      ],
      "metadata": {
        "cellView": "form",
        "id": "zGQotX_akpYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Save performance metrics to CSV\n",
        "metrics_df = pd.DataFrame(results)\n",
        "metrics_df.to_csv('/content/model_performance_metrics.csv', index=False)\n",
        "print(\"Model performance metrics saved to /content/model_performance_metrics_best.csv\")\n",
        "\n",
        "# Save or output results as needed\n",
        "output_file_path = '/content/qsar_results_best.csv'\n",
        "results_df = pd.DataFrame({\n",
        "    'SMILES': data['SMILES'],\n",
        "    'Actual Activity': target,\n",
        "    'Predicted Activity (Best Model)': best_model.predict(features_scaled) if best_model else np.nan\n",
        "})\n",
        "results_df.to_csv(output_file_path, index=False)\n",
        "print(f\"QSAR results saved to {output_file_path}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "v7LFnI2llGS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Save the best model\n",
        "import joblib  # Ensure this line is included at the beginning of your script\n",
        "\n",
        "# Save the best model\n",
        "if best_model:\n",
        "    model_filename = '/content/best_model.pkl'\n",
        "    joblib.dump(best_model, model_filename)\n",
        "    print(f\"Best model ({best_model_name}) saved to {model_filename}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "6SHZ2RGcmRQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Plot Actual vs. Predicted Activity for Best Model\n",
        "plt.figure(figsize=(14, 7))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.scatterplot(x=y_test, y=best_model.predict(X_test), alpha=0.7)\n",
        "plt.xlabel('Actual Activity')\n",
        "plt.ylabel('Predicted Activity')\n",
        "plt.title(f'Actual vs. Predicted Activity ({best_model_name})')\n",
        "\n",
        "# Add the ideal line where y = x\n",
        "min_val = min(y_test.min(), best_model.predict(X_test).min())\n",
        "max_val = max(y_test.max(), best_model.predict(X_test).max())\n",
        "plt.plot([min_val, max_val], [min_val, max_val], color='red', linestyle='--', label='Ideal Line')\n",
        "plt.legend()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "dd2CMkxpmbxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Plot Residuals for Best Model\n",
        "plt.subplot(1, 2, 2)\n",
        "residuals = y_test - best_model.predict(X_test)\n",
        "sns.histplot(residuals, kde=True)\n",
        "plt.xlabel('Residuals')\n",
        "plt.title('Residuals Plot')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/best_model_plots.png')\n",
        "print(\"Best model plots saved to /content/best_model_plots.png\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "qPMnDfhHm0xI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Feature Importance Plot for Best Model\n",
        "if best_model_name in ['Random Forest', 'Gradient Boosting']:\n",
        "    importances = best_model.feature_importances_\n",
        "    importance_df = pd.DataFrame({\n",
        "        'Feature': features.columns,\n",
        "        'Importance': importances\n",
        "    })\n",
        "    importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    sns.barplot(x='Importance', y='Feature', data=importance_df)\n",
        "    plt.title(f'Feature Importance ({best_model_name})')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'/content/{best_model_name.lower().replace(\" \", \"_\")}_feature_importance.png')\n",
        "    print(f\"Feature importance plot for {best_model_name} saved to /content/{best_model_name.lower().replace(' ', '_')}_feature_importance.png\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "bw1WmMpVm_A0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Testing Unknown Datset with the best model**"
      ],
      "metadata": {
        "id": "BrvrwD9EpNRM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load the best model\n",
        "model_filename = '/content/best_model.pkl'\n",
        "best_model = joblib.load(model_filename)\n",
        "print(f\"Best model loaded from {model_filename}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "qCV5tOCppRb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now calculate the same features for the unknown dataset, as we have calculated in the previous section. Bring that data here and load it below"
      ],
      "metadata": {
        "id": "MAHc7I6EpaAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import required libraries\n",
        "import pandas as pd\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import joblib"
      ],
      "metadata": {
        "cellView": "form",
        "id": "jXbZkwvEpszL"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load new compounds\n",
        "new_data = pd.read_csv('/content/unknown.csv')"
      ],
      "metadata": {
        "id": "0gNWkoyup6mj"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Extract feature columns (assuming all columns except SMILES and Activity are features)\n",
        "feature_columns = [col for col in new_data.columns if col not in ['SMILES', 'Activity']]\n",
        "new_data_features = new_data[feature_columns]\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "-Fz3AcGKqJIc"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Scale the new data if applicable\n",
        "new_data_scaled = scaler.transform(new_data_features)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "TPHtpvdUrBj1"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Perform predictions with the best model\n",
        "predictions = best_model.predict(new_data_scaled)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "kPg-NzNRrEww"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Add predictions to the DataFrame\n",
        "new_data['Predicted_Activity'] = predictions"
      ],
      "metadata": {
        "cellView": "form",
        "id": "SqGwjEoqrIlm"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Save results to a CSV file\n",
        "new_data.to_csv('/content/predicted_activities_unknown.csv', index=False)\n",
        "print(\"Predictions saved to /content/result_for_unknown.csv\")"
      ],
      "metadata": {
        "id": "HpP8Z-tQrNGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Research Directions and applications**\n",
        "are discussed in [**Tutorial Video**](https://youtu.be/KSz0sQM13K0)\n",
        "\n",
        "1. Virtual Screening\n",
        "\n",
        "2. Exploratory Data Analysis\n",
        "\n",
        "3. Compound Library of Unknown compounds Generation\n",
        "\n"
      ],
      "metadata": {
        "id": "vDAzyiB0fwdj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Congratulation**, You did it.\n",
        "\n",
        "I am sure, you have learned something new in this One hour time.\n",
        "If you are happy, please Subscribe My Youtube Channel [**Bioinformatics Insights**](https://www.youtube.com/@Bioinformaticsinsights).\n",
        "\n",
        "Also if you want to stay connected for updates, courses, and computational services, you can follow this Whatsapp Channel [**BinfoLab**](https://whatsapp.com/channel/0029VajkwkdCHDydS6Y2lM36)."
      ],
      "metadata": {
        "id": "uEvntlsBi9x3"
      }
    }
  ]
}