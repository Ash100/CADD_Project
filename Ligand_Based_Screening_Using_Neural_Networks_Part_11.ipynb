{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ash100/CADD_Project/blob/main/Ligand_Based_Screening_Using_Neural_Networks_Part_11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8H-t8oAUts2v"
      },
      "source": [
        "# PART-11: Ligand-Based Screening Using Neural Networks\n",
        "\n",
        "My name is **Dr. Ashfaq Ahmad** and you can watch complete tutorial of this notebook on [**Bioinformatics Insights**](https://www.youtube.com/channel/UC2Z_WaqTjbvXGGQNpIF9nAg). This talktorial is inspired from TeachOpenCADD, a platform that aims to teach domain-specific skills and to provide pipeline templates as starting points for research projects. Majority of scripts are modified or changed accordingly.\n",
        "\n",
        "Authors:\n",
        "\n",
        "- Ahmed Atta, CADD Seminar 2020, Charité/FU Berlin\n",
        "- Sakshi Misra, internship (2020/21), [Volkamer lab](https://volkamerlab.org), Charité\n",
        "- Talia B. Kimber, 2020/21, [Volkamer lab](https://volkamerlab.org), Charité\n",
        "- Andrea Volkamer, 2021, [Volkamer lab](https://volkamerlab.org), Charité"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXg9Y1Dgts2y"
      },
      "source": [
        "## Aim of this talktorial\n",
        "\n",
        "In recent years, the use of machine learning, and deep learning, in pharmaceutical research has shown promising results in addressing diverse problems in drug discovery. In this talktorial, we get familiar with the basics of neural networks. We will learn how to build a simple two layer neural network and train it on a subset of ChEMBL data in order to predict the pIC50 values of compounds against EGFR, the target of interest. Furthermore, we select three compounds from an external, unlabeled data set that are predicted to be the most active against that kinase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSmYcRhpts2z"
      },
      "source": [
        "### Contents in *Theory*\n",
        "\n",
        "- Biological background\n",
        "    - EGFR kinase\n",
        "    - Compound activity measures\n",
        "    - Molecule encoding\n",
        "- Neural networks\n",
        "    - What is a neural network?\n",
        "    - Activation function\n",
        "    - Loss function\n",
        "- Training a neural network\n",
        "- Keras workflow\n",
        "- Advantages and applications of neural networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqALF4NCts20"
      },
      "source": [
        "### References\n",
        "\n",
        " - Theoretical background:\n",
        "     - Articles    \n",
        "         - Siddharth Sharma, \"Activation functions in neural networks\". [_International Journal of Engineering Applied Sciences and Technology, 2020_ **Vol. 4, Issue 12,** 310-316 (2020).](https://www.ijeast.com/papers/310-316,Tesma412,IJEAST.pdf)\n",
        "         - Shun-ichi Amari, \"Backpropagation and stochastic gradient descent method\", [*ScienceDirect  **Volume 5, Issue 4-5**, 185-196*](https://doi.org/10.1016/0925-2312(93)90006-O)\n",
        "         - Gisbert Schneider et al., \"Artificial neural networks for computer-based molecular design\", [*ScienceDirect **Volume 70, Issue 3**, 175-222*](https://doi.org/10.1016/S0079-6107(98)00026-1)\n",
        "         - Filippo Amato et al., \"Artificial neural networks in medical diagnosis\", [*ScienceDirect  **Volume 11, Issue 2**, 47-58*](https://doi.org/10.2478/v10136-012-0031-x)         \n",
        "         \n",
        "     - Blogposts\n",
        "          - Imad Dabbura, *Coding Neural Network — Forward Propagation and Backpropagtion*, [towardsdatascience, accessed April 1st, 2018](https://towardsdatascience.com/coding-neural-network-forward-propagation-and-backpropagtion-ccf8cf369f76).\n",
        "          - Lavanya Shukla, *Designing Your Neural Networks*, [towardsdatascience, accessed Sep 23rd, 2019](https://towardsdatascience.com/designing-your-neural-networks-a5e4617027ed)\n",
        "          - Arthur Arnx, *First neural network for beginners explained (with code)*, [towardsdatascience, accessed Jan 13th, 2019](https://towardsdatascience.com/first-neural-network-for-beginners-explained-with-code-4cfd37e06eaf)\n",
        "          - Varun Divakar, *Understanding Backpropagation*, [QuantInst, accessed Nov 19th, 2018](https://blog.quantinsti.com/backpropagation/)\n",
        "               \n",
        "- Packages:\n",
        "     - [rdkit](http://rdkit.org/): Greg Landrum, *RDKit Documentation*, [PDF](https://www.rdkit.org/UGM/2012/Landrum_RDKit_UGM.Fingerprints.Final.pptx.pdf), Release on 2019.09.1.\n",
        "     - [Keras](https://keras.io/): Book chapter: \"An Introduction to Deep Learning and Keras\" in [*Learn Keras for Deep Neural Networks* (2019), **page(s):1-16**](https://doi.org/10.1007/978-1-4842-4240-7).\n",
        "     - [Sequential model](https://keras.io/api/models/sequential/) in keras\n",
        "     - [Model training APIs](https://keras.io/api/models/model_training_apis/#model-training-apis)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hwpMQjCts20"
      },
      "source": [
        "## Theory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxeMdiIkts21"
      },
      "source": [
        "### Biological background"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc-hr-collapsed": true,
        "toc-nb-collapsed": true,
        "id": "RluFHV-Hts21"
      },
      "source": [
        "#### EGFR kinase\n",
        "\n",
        "- The [Epidermal Growth Factor Receptor (EGFR)](https://en.wikipedia.org/wiki/Epidermal_growth_factor_receptor) is a transmembrane protein/receptor present on the cell membrane. It is a member of the ErbB family of receptors.\n",
        "- EGFR plays an important role in controlling normal cell growth, apoptosis and other cellular functions.\n",
        "- It is activated by ligand binding to its extracellular domain, upon activation EGFR undergoes a transition from an inactive monomeric form to an active homodimers.\n",
        "- The EGFR receptor is upregulated in various types of tumors or cancers, so an EGFR inhibition is a type of biological therapy that might stop cancer cells from growing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4cDrqzIts21"
      },
      "source": [
        "#### Compound activity measures\n",
        "\n",
        "- **IC50** is the half maximal inhibitory concentration of a drug which indicates how much of a drug is needed to inhibit a biological process by half.\n",
        "- **pIC50** is the negative logarithm of the IC50 value. It is more easily interpretable than IC50 values and a common measure for potency of compounds (see [**Part-1**](https://youtu.be/JHrzoeTH8_k?si=CDMtm1q4G6JpnlSt) for further details)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LE1sKPnkts22"
      },
      "source": [
        "#### Molecule encoding\n",
        "\n",
        "For machine learning algorithms, molecules need to be converted into a machine readable format, e.g. a list of features. In this notebook, molecular fingerprints are used. For proper details please see [**Part3**](https://youtu.be/-AS_QbFyyTk?si=e8nb68uI-c9Nlx6_).\n",
        "\n",
        "Molecular fingerprints encode chemical structures and molecular features in a bit string, where at each position \"1\" represents the presence and \"0\" represents the absence of a feature. One of the common fingerprints used are **M**olecular **ACC**ess **S**ystem fingerprints [(MACCS Keys)](https://docs.eyesopen.com/toolkits/python/graphsimtk/fingerprint.html#maccs) which are 166 bits structural key descriptors in which each bit is associated with a [SMARTS](https://docs.eyesopen.com/toolkits/python/oechemtk/glossary.html#term-smarts) pattern encoding a specific substructure."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tc6YfL2Gts22"
      },
      "source": [
        "### Neural networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhcJpLx7ts22"
      },
      "source": [
        "#### What is a neural network?\n",
        "\n",
        "Neural networks, also known as artificial neural networks (ANNs), are a subset of machine learning algorithms. The structure and the name of the neural network is inspired by the human brain, mimicking the way that biological neurons transfer signals to one another.\n",
        "\n",
        "![Basic structure](https://github.com/volkamerlab/teachopencadd/blob/master/teachopencadd/talktorials/T022_ligand_based_screening_neural_network/images/basic_structure.png?raw=1)\n",
        "\n",
        "*Figure 1:* The figure shows the basic structure of an artificial neural network. It is taken from the blogpost: \"*Designing Your Neural Networks*\", Lavanya Shukla, [towardsdatascience](https://towardsdatascience.com/designing-your-neural-networks-a5e4617027ed)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SX8FbTUJts22"
      },
      "source": [
        "ANNs consist of three main layers as shown in the figure above: the _input layer_, some _hidden layers_ and the _output layer_. Let's take a deeper look at each of them.\n",
        "\n",
        "1. **Input neurons or input layer**\n",
        "   - This layer represents the number of features which are used to make the predictions.\n",
        "   - The input vector needs one input neuron per feature.\n",
        "2. **Hidden layers and neurons per hidden layer**\n",
        "    - The dimension of the hidden layers may vary greatly, but a good rule of thumb is to have dimensions in the range of the input layer and the output layer.\n",
        "    - In general, using the same number of neurons for all hidden layers will suffice but for some datasets, having a large first layer and following it up with smaller layers may lead to a better performance as first layers can learn many low-level features.\n",
        "3. **Output neurons or output layer**\n",
        "    - The output layer represents the value of interest, which will be predicted by the neural network.\n",
        "        - Regression task: the value is a real number (or vector) such as the pIC50 value.\n",
        "        - Binary classification task: the output neuron represents the probability of belonging to the positive class.\n",
        "        - Multi-class classification task: there is one output neuron per class and the predictions represent the probability of belonging to each class. A certain activation function is applied on the output layer to ensure the final probabilities sum up to 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEpErCFsts22"
      },
      "source": [
        "**Neurons** are the core units of a neural network. Let's look into the operations done by each neuron to understand the overall mechanism of a neural network.\n",
        "\n",
        "![Neuron](https://github.com/volkamerlab/teachopencadd/blob/master/teachopencadd/talktorials/T022_ligand_based_screening_neural_network/images/neuron.png?raw=1)\n",
        "\n",
        "*Figure 2:* Operations done by a neuron. The figure is taken from the blogpost: \"*First neural network for beginners explained (with code)*\", Arthur Arnx, [towardsdatascience](https://towardsdatascience.com/first-neural-network-for-beginners-explained-with-code-4cfd37e06eaf)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZIOKY16ts22"
      },
      "source": [
        "Each input neuron $x_i$ is multiplied by a weight $w_i$. In Figure 2, we have $(x1, x2, x3)$ and  $(w1, w2, w3)$. The value of a weight determines the influence that the input neuron will have on the neuron of the next layer. The multiplied values are then summed. An additional value, called bias, is also added and allows to shift the activation function. This new value becomes the value of the hidden neuron. Mathematically, we have:\n",
        "\n",
        "$$ h = (w1*x1 + w2*x2 + w3*x3) + b = \\sum_i ^ 3w_i*x_i+ b $$\n",
        "\n",
        "An activation function, discussed in greater details in the next section, is then applied to the hidden neuron to determine if the neuronal value should be activated or not. An activated neuron transmits data to the neuron of the next layer. In this manner, the data is propagated through the network which is known as [forward propagation](https://en.wikipedia.org/wiki/Feedforward_neural_network).\n",
        "\n",
        "The weights and biases in a neural network are referred to as **_learnable parameters_**. They are tuned when training the model to obtain a good performance.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4SHyAICts22"
      },
      "source": [
        "#### Activation function\n",
        "\n",
        "**What is an activation function?**\n",
        "\n",
        "An [activation function](https://en.wikipedia.org/wiki/Activation_function) regulates the amount of information passed through a neural network. This function is applied to each neuron and determines whether the neuron should be activated or not. It works as a \"gate\" between the input feeding the current neuron and its output going to the next layer as shown in the figure below.\n",
        "\n",
        "![Activation](https://github.com/volkamerlab/teachopencadd/blob/master/teachopencadd/talktorials/T022_ligand_based_screening_neural_network/images/activation.png?raw=1)\n",
        "\n",
        "*Figure 3:* The figure shows an activation function applied on a neuron. It is taken from the blogpost: [Why Activation Functions?](https://medium.com/analytics-vidhya/why-activation-functions-8328f3f21120)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Xb-7Drjts22"
      },
      "source": [
        "**Types of activation function**\n",
        "\n",
        "There are many types of activation functions, but we only discuss the two which we use in the practical section below. For more information, see the supplementary section and references. Most neural networks use non-linear activation functions in the hidden layers to learn complex features and adapt to a variety of data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWmTyv8nts23"
      },
      "source": [
        "1. Rectified Linear Unit (ReLU)\n",
        "\n",
        "- It takes the form: $\\boxed{f(x) = max\\{ 0, x\\}}$.\n",
        "- As shown in the figure below, [ReLU](https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/) outputs $x$, if $x$ is positive and $0$ otherwise. The range of ReLU is $[0, +\\infty)$.\n",
        "- One of the reasons it is commonly used is its sparsity: only few neurons will be activated and thereby making the activations sparse and efficient.\n",
        "- It has become the default activation function for many types of neural networks because it makes the training of a model less expensive and the model often achieves better performance.\n",
        "- A possible drawback of ReLU is the so-called _dying ReLU problem_ where neurons get stuck as inactive for all inputs, it is a form of [vanishing gradient problem](https://en.wikipedia.org/wiki/Vanishing_gradient_problem).\n",
        "\n",
        "![ReLU](https://github.com/volkamerlab/teachopencadd/blob/master/teachopencadd/talktorials/T022_ligand_based_screening_neural_network/images/relu.png?raw=1)\n",
        "\n",
        "*Figure 4:* Representation of the *ReLU* function. Figure by Sakshi Misra."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dY_9Bwuts23"
      },
      "source": [
        "2. Linear activation function\n",
        "\n",
        "- A [linear activation function](https://keras.io/api/layers/core_layers/dense/) takes the form: $\\boxed{a(x) = x}$.\n",
        "- It is the most appropriate activation function in a regression setting, since there is no constraint on the output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4t22c4eDts23"
      },
      "source": [
        "#### Loss function\n",
        "\n",
        "\n",
        "When training a neural network, the aim is to optimize the prediction error, i.e. the difference between the true value and the value predicted by the model. The prediction error can be written as a function, known as the objective function, cost function, or **loss function**. The goal is therefore to minimize the loss function, in other words, to find local minima. The loss function is one of the important components in training a neural network. For more details on loss functions, please refer to the blogpost: [Loss and Loss Functions for Training Deep Learning Neural Networks](https://machinelearningmastery.com/loss-and-loss-functions-for-training-deep-learning-neural-networks/).\n",
        "Two commonly used loss functions in regression tasks are\n",
        "\n",
        "1. the **Mean Squared Error (MSE)**: As the name suggests, this loss is calculated by taking the mean of the squared differences between the true and predicted values.\n",
        "2. the **Mean Absolute Error (MAE)**: The loss is calculated by taking the mean of the absolute difference between the true and predicted values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiYmWaVZts23"
      },
      "source": [
        "### Training a neural network\n",
        "\n",
        "When starting with a neural network, the parameters, i.e. the weights and biases, are randomly initialized. The inputs are then fed into the network and produce an output. However, the corresponding output will most likely be very different from the true value. In other words, the prediction error will be very poor: the loss function is far from being minimal. Therefore, the initial parameters have to be optimized to obtain better predictions.\n",
        "\n",
        "To this end, we need to minimize the loss function. An efficient way to find such a minimum is to use the [gradient descent](https://en.wikipedia.org/wiki/Gradient_descent#:~:text=Gradient%20descent%20is%20a%20first,the%20direction%20of%20steepest%20descent.) algorithm. This optimization scheme is iterative and uses both the derivative of the loss function (or gradient in the multivariate case) and a learning rate. The main idea behind the algorithm is to follow the steepest direction of the function, obtained with the gradient and managing the length of each step with the learning rate. The latter is often referred to as a hyperparameter, which can be tuned using cross-validation (more details in future talktorials).\n",
        "\n",
        "In training neural networks, it is very common to use _back-propagation_, which is a way of efficiently obtaining the gradients using the chain-rule for differentiation.\n",
        "\n",
        "In summary, after each forward pass through a network, back-propagation performs a backward pass while adjusting the model’s parameters in order to minimize the loss function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rb4pRB7hts23"
      },
      "source": [
        "**Computation cost**\n",
        "\n",
        "If the data set used is very large, computing the gradient of the loss function can be very expensive. A way to solve this issue is to use instead a sample, or mini-batch, of the training data at a time, known as [_Stochastic Gradient Descent (SGD)_](https://en.wikipedia.org/wiki/Stochastic_gradient_descent) or _Mini-Batch Stochastic Gradient Descent_."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KD9mgWx_ts23"
      },
      "source": [
        "### Keras workflow\n",
        "\n",
        "[Keras](https://keras.io/getting_started/) is an open-source library for machine learning and more specifically neural networks. Its API runs on top of the very well-known [tensorflow](https://www.tensorflow.org/) deep learning platform.\n",
        "\n",
        "Below, we present a common workflow for training a neural network with [keras](https://keras.io/getting_started/).\n",
        "\n",
        "\n",
        "- **Prepare the data** − Foremost for any machine learning algorithm, we process, filter and select only the required information from the data. Then, the data is split into training and test data sets. The test data is used to evaluate the prediction of the algorithm and to cross check the efficiency of the learning process.\n",
        "\n",
        "\n",
        "- **Define the model** - In keras, every ANN is represented by keras [models](https://keras.io/api/models/model/#model-class). Keras provides a way to create a model which is called [sequential](https://keras.io/api/models/sequential/). The layers are arranged sequentially where the data flows from one layer to another layer in a given order until the data finally reaches the output layer. Each layer in the ANN can be represented by a *keras layer*.\n",
        "\n",
        "\n",
        "- **Compile the model** − The compilation is the final step in creating a model. Once the compilation is done, we can move on to the training phase. A _loss function_ and an _optimizer_ are required in the learning phase to define the prediction error and to minimize it, respectively. In the practical part of this talktorial, we use the mean squared error as a loss and the [adam](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/) optimizer, which is a popular version of gradient descent and has shown to give good results in a wide range of problems.\n",
        "\n",
        "- **Fit the model** - The actual learning process will be done in this phase using the training data set. We can call the [fit()](https://keras.io/api/models/model_training_apis/#fit-method) method which needs several parameters such as $x$ the input data, $y$ the target data, the batch size, the number of epochs, etc. An _epoch_ is when the entire dataset is passed forward and backward through the neural network once.\n",
        "\n",
        "- **Evaluate model** − We can evaluate the model by looking at the loss function between the predicted and true values of the test data using the [evaluate()](https://keras.io/api/models/model_training_apis/#evaluate-method) method.\n",
        "\n",
        "    - Scatter plots are a common and simple approach to visualize the evaluation of a model. They plot the predicted vs. true values. If the fit was perfect, we should see the $y=x$ line, meaning that the predicted value is exactly the true value.\n",
        "    \n",
        "    \n",
        "- **Predictions on external/unlabeled data** − We make predictions based on the trained model for the external data set using the [predict()](https://keras.io/api/models/model_training_apis/#predict-method) method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4JbMCbSts23"
      },
      "source": [
        "### Advantages and applications of neural networks\n",
        "\n",
        "**Advantages of a neural network**\n",
        "\n",
        "- **Organic learning**: Neural networks have the ability to learn by extracting the important features present in the input data.\n",
        "- **Non linear data processing**: They have the ability to learn and model non-linear and complex relationships.\n",
        "- **Time operation**: The computation cost during training time can be reduced using parallelization.\n",
        "\n",
        "To learn more about advantages and disadvantages of a neural network, please refer to the article: J V Tu, \"*Advantages and disadvantages of using artificial neural networks versus logistic regression for predicting medical outcomes*\", [Journal of Clinical Epidemiology, **vol 49 issue 11**, pages: 1225-1231](https://pubmed.ncbi.nlm.nih.gov/8892489/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPXHes3qts23"
      },
      "source": [
        "**Applications of neural networks**\n",
        "\n",
        "There are various applications of neural networks in computer-aided drug design  such as:\n",
        "\n",
        "- Drug design and discovery\n",
        "- Biomarker identification and/or classification\n",
        "- Various types of cancer detection\n",
        "- Pattern recognition\n",
        "\n",
        "Please refer to the article: Cheirdaris D.G. (2020), \"*Artificial Neural Networks in Computer-Aided Drug Design: An Overview of Recent Advances*\",  [GeNeDis 2018. Advances in Experimental Medicine and Biology, **vol 1194**. Springer](https://link.springer.com/chapter/10.1007/978-3-030-32622-7_10) for more details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrKYuBv_ts23"
      },
      "source": [
        "## Practical\n",
        "\n",
        "The first step is to import all the necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Install Conda - Kernal Restart will take place\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ],
      "metadata": {
        "id": "O-kQWNk-xQZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install mamba\n",
        "!conda install -c conda-forge mamba -y\n",
        "!mamba install -q -y -c conda-forge pandas matplotlib seaborn rdkit"
      ],
      "metadata": {
        "id": "gGn5nBuExRaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade keras\n",
        "!pip install --upgrade scikit_learn"
      ],
      "metadata": {
        "id": "SFE71mkGyEqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JQheMQryts23"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from warnings import filterwarnings\n",
        "\n",
        "# Silence some expected warnings\n",
        "filterwarnings(\"ignore\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import MACCSkeys, Draw, rdFingerprintGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "import seaborn as sns\n",
        "\n",
        "# Neural network specific libraries\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xtbZkyrts24"
      },
      "source": [
        "### Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc7tMKmIts25"
      },
      "source": [
        "Let's load the data which is a subset of ChEMBL for EGFR. The important columns in the dataframe are:\n",
        "\n",
        "- CHEMBL-ID\n",
        "- SMILES string of the corresponding compound\n",
        "- Measured affinity: pIC50"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we will use the data produced in Part_1. Once you successfully run Part_1, please open the CSV file, which is already downloaded into your computer. From there, remove the IC50, and nm column. You will have three columns left. Index, chemble_id, smiles, and PIC50. Save this file using the save as button, and upload it here."
      ],
      "metadata": {
        "id": "j7r9i2QSla8Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "tags": [],
        "id": "4FnMNr1Ots25"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "df = pd.read_csv(\"/content/sample_data/EGFR_compounds_new.csv\")\n",
        "df = df.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "ynFAYM1tts25"
      },
      "outputs": [],
      "source": [
        "# Check the dimension and missing value of the data\n",
        "print(\"Shape of dataframe : \", df.shape)\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "8QMXzUrhts25"
      },
      "outputs": [],
      "source": [
        "# Look at head\n",
        "df.head()\n",
        "# NBVAL_CHECK_OUTPUT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "11fHTS7Sts25"
      },
      "outputs": [],
      "source": [
        "# Keep necessary columns\n",
        "chembl_df = df[[\"smiles\", \"pIC50\"]]\n",
        "chembl_df.head()\n",
        "# NBVAL_CHECK_OUTPUT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pj6692Kyts26"
      },
      "source": [
        "**Molecular encoding**\n",
        "\n",
        "We convert the SMILES string to numerical data to apply a neural network. We use the already defined function `smiles_to_fp` from **Part_3** which generates fingerprints from SMILES."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "tags": [],
        "id": "b1_4rqZ8ts26"
      },
      "outputs": [],
      "source": [
        "def smiles_to_fp(smiles, method=\"maccs\", n_bits=2048):\n",
        "    \"\"\"\n",
        "    Encode a molecule from a SMILES string into a fingerprint.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    smiles : str\n",
        "        The SMILES string defining the molecule.\n",
        "\n",
        "    method : str\n",
        "        The type of fingerprint to use. Default is MACCS keys.\n",
        "\n",
        "    n_bits : int\n",
        "        The length of the fingerprint.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    array\n",
        "        The fingerprint array.\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert smiles to RDKit mol object\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "\n",
        "    if method == \"maccs\":\n",
        "        return np.array(MACCSkeys.GenMACCSKeys(mol))\n",
        "    if method == \"morgan2\":\n",
        "        fpg = rdFingerprintGenerator.GetMorganGenerator(radius=2, fpSize=n_bits)\n",
        "        return np.array(fpg.GetCountFingerprint(mol))\n",
        "    if method == \"morgan3\":\n",
        "        fpg = rdFingerprintGenerator.GetMorganGenerator(radius=3, fpSize=n_bits)\n",
        "        return np.array(fpg.GetCountFingerprint(mol))\n",
        "    else:\n",
        "        print(f\"Warning: Wrong method specified: {method}.\" \" Default will be used instead.\")\n",
        "        return np.array(MACCSkeys.GenMACCSKeys(mol))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AblQiT1ts27"
      },
      "source": [
        "Convert all SMILES strings to MACCS fingerprints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "M242y_W7ts27"
      },
      "outputs": [],
      "source": [
        "chembl_df[\"fingerprints_df\"] = chembl_df[\"smiles\"].apply(smiles_to_fp)\n",
        "\n",
        "# Look at head\n",
        "print(\"Shape of dataframe:\", chembl_df.shape)\n",
        "chembl_df.head(3)\n",
        "# NBVAL_CHECK_OUTPUT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ruE8-U8ts28"
      },
      "source": [
        "Next, we define $x$, the **features**, and $y$, the **target data** which will be used to train the model. In our case, features are the bit vectors and the target values are the pIC50 values of the molecules.\n",
        "\n",
        "We use `train_test_split` from the _scikit-learn_ library to split the data into 70% training and 30% test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "lQ6p8Fcpts2_"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and test set\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    chembl_df[\"fingerprints_df\"], chembl_df[[\"pIC50\"]], test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Print the shape of training and testing data\n",
        "print(\"Shape of training data:\", x_train.shape)\n",
        "print(\"Shape of test data:\", x_test.shape)\n",
        "# NBVAL_CHECK_OUTPUT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dp5tnv64ts2_"
      },
      "source": [
        "### Define neural network\n",
        "\n",
        "A keras model is defined by specifying the number of neurons in the hidden layers and the activation function as arguments. For our purpose, we define a model with *two hidden layers*. We use ReLU in the hidden layers and a linear function on the output layer, since the aim is to predict pIC50 values.\n",
        "Finally, we compile the model using the *mean squared error* as a loss argument and *adam* as an optimizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "tags": [],
        "id": "o16C64-Ats3A"
      },
      "outputs": [],
      "source": [
        "def neural_network_model(hidden1, hidden2):\n",
        "    \"\"\"\n",
        "    Creating a neural network from two hidden layers\n",
        "    using ReLU as activation function in the two hidden layers\n",
        "    and a linear activation in the output layer.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    hidden1 : int\n",
        "        Number of neurons in first hidden layer.\n",
        "\n",
        "    hidden2: int\n",
        "        Number of neurons in second hidden layer.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    model\n",
        "        Fully connected neural network model with two hidden layers.\n",
        "    \"\"\"\n",
        "\n",
        "    model = Sequential()\n",
        "    # First hidden layer\n",
        "    model.add(Dense(hidden1, activation=\"relu\", name=\"layer1\"))\n",
        "    # Second hidden layer\n",
        "    model.add(Dense(hidden2, activation=\"relu\", name=\"layer2\"))\n",
        "    # Output layer\n",
        "    model.add(Dense(1, activation=\"linear\", name=\"layer3\"))\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"mse\", \"mae\"])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRo-i95zts3A"
      },
      "source": [
        "### Train the model\n",
        "\n",
        "We try different mini-batch sizes and plot the respective losses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "tags": [],
        "id": "L28HvhoHts3A"
      },
      "outputs": [],
      "source": [
        "# Neural network parameters\n",
        "batch_sizes = [16, 32, 64]\n",
        "nb_epoch = 50\n",
        "layer1_size = 64\n",
        "layer2_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "9W0KC9p4ts3A"
      },
      "outputs": [],
      "source": [
        "# Plot\n",
        "fig = plt.figure(figsize=(12, 6))\n",
        "sns.set(color_codes=True)\n",
        "for index, batch in enumerate(batch_sizes):\n",
        "    fig.add_subplot(1, len(batch_sizes), index + 1)\n",
        "    model = neural_network_model(layer1_size, layer2_size)\n",
        "\n",
        "    # Fit model on x_train, y_train data\n",
        "    history = model.fit(\n",
        "        np.array(list((x_train))).astype(float),\n",
        "        y_train.values,\n",
        "        batch_size=batch,\n",
        "        validation_data=(np.array(list((x_test))).astype(float), y_test.values),\n",
        "        verbose=0,\n",
        "        epochs=nb_epoch,\n",
        "    )\n",
        "    plt.plot(history.history[\"loss\"], label=\"train\")\n",
        "    plt.plot(history.history[\"val_loss\"], label=\"test\")\n",
        "    plt.legend([\"train\", \"test\"], loc=\"upper right\")\n",
        "    plt.ylabel(\"loss\")\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.ylim((0, 15))\n",
        "    plt.title(\n",
        "        f\"test loss = {history.history['val_loss'][nb_epoch-1]:.2f}, \" f\"batch size = {batch}\"\n",
        "    )\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEbWKohYts3B"
      },
      "source": [
        "From the loss plots above, a batch of size 64 seems to give the best performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUEVa51Hts3B"
      },
      "source": [
        "A [_ModelCheckpoint callback_](https://keras.io/api/callbacks/) is used to save the best model/weights (in a checkpoint file) at some interval, so the model/weights can either be saved as it or be loaded later to continue the training from the state saved.\n",
        "\n",
        "Now, we train the model with a batch size of 64 (because as seen from the figure above, it has the lowest test loss) and we save the weights that give the best perfomance in the file `best_weights.hdf5`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "9zAwDmRNts3B"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "import numpy as np\n",
        "\n",
        "# Save the trained model\n",
        "filepath = \"/content/sample_data/best_weights.weights.h5\"\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath,\n",
        "    monitor=\"loss\",\n",
        "    verbose=0,\n",
        "    save_best_only=True,\n",
        "    mode=\"min\",\n",
        "    save_weights_only=True,\n",
        ")\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "# Fit the model\n",
        "model.fit(\n",
        "    np.array(list((x_train))).astype(float),\n",
        "    y_train.values,\n",
        "    epochs=nb_epoch,\n",
        "    batch_size=64,\n",
        "    callbacks=callbacks_list,\n",
        "    verbose=0,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fj7Jdg6Vts3B"
      },
      "source": [
        "### Evaluation & prediction on test set\n",
        "\n",
        "The [evaluate()](https://keras.io/api/models/model_training_apis/#evaluate-method) method is used to check the performance of our model. It reports the **loss** (which is the mse in our case) as well as evaluation metrics (which are the **mse** and **mae**)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "RqUgrzdWts3B"
      },
      "outputs": [],
      "source": [
        "# Evalute the model\n",
        "print(f\"Evaluate the model on the test data\")\n",
        "scores = model.evaluate(np.array(list((x_test))), y_test.values, verbose=0)\n",
        "print(f\" loss: {scores[0]:.2f}\")\n",
        "print(f\" mse (same as loss): {scores[1]:.2f}\")\n",
        "print(f\" mae: {scores[2]:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuWpW5ngts3C"
      },
      "source": [
        "The mean absolute error on the test set is as below $1.0$ which given the range of pIC50 values is pretty low.\n",
        "\n",
        "We now predict the pIC50 values on the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "n56fA38ats3C"
      },
      "outputs": [],
      "source": [
        "# Predict pIC50 values on x_test data\n",
        "y_pred = model.predict(np.array(list((x_test))))\n",
        "\n",
        "# Print 5 first pIC50 predicted values\n",
        "first_5_prediction = [print(f\"{value[0]:.2f}\") for value in y_pred[0:5]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUel7HB3ts3C"
      },
      "source": [
        "#### Scatter plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OclSgVYEts3D"
      },
      "source": [
        "To visualize the predictions, we plot the predicted vs. the true pIC50 values on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "nbsphinx-thumbnail"
        ],
        "id": "U2K1Qn5-ts3D"
      },
      "outputs": [],
      "source": [
        "# Scatter plot\n",
        "limits = 0, 15\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(y_pred, y_test, marker=\".\")\n",
        "lin = np.linspace(*limits, 100)\n",
        "ax.plot(lin, lin)\n",
        "ax.set_aspect(\"equal\", adjustable=\"box\")\n",
        "ax.set_xlabel(\"Predicted values\")\n",
        "ax.set_ylabel(\"True values\")\n",
        "ax.set_title(\"Scatter plot: pIC50 values\")\n",
        "ax.set_xlim(limits)\n",
        "ax.set_ylim(limits)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yrUNk-bts3D"
      },
      "source": [
        "As we can see, there is a positive linear relation between the predicted and true values, but the fit is far from perfect."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import model_from_json\n",
        "\n",
        "# Serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "\n",
        "# Serialize weights to HDF5\n",
        "model.save_weights(\"model.weights.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "metadata": {
        "id": "FXyfHldpevR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dL2glWbts3D"
      },
      "source": [
        "### Prediction on external/unlabeled data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FGH6hc2ts3D"
      },
      "source": [
        "We use the trained neural network to predict the pIC50 values on the unlabeled compounds from the `test.csv`file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "tags": [],
        "id": "UPVTkbuots3D",
        "outputId": "c3d377c5-9420-461f-866f-b16b3e71869f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Unnamed: 1                                   canonical_smiles\n",
              "0  Gefatinib  COC1=C(C=C2C(=C1)N=CN=C2NC3=CC(=C(C=C3)F)Cl)OC...\n",
              "1  ibuprofen                      CC(C)CC1=CC=C(C=C1)C(C)C(=O)O\n",
              "2    pyrazol  CC1=C(C=C(C=C1)C2=NN(C(C2)C3=CC=C(C=C3)OC)C(=S...\n",
              "3    chlorop      CC(C)N1C2=NC=NC(=C2C(=N1)C3=CC(=C(C=C3)Cl)O)N"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-297f1b3d-c726-4e4e-abf7-8f850c281d0d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 1</th>\n",
              "      <th>canonical_smiles</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Gefatinib</td>\n",
              "      <td>COC1=C(C=C2C(=C1)N=CN=C2NC3=CC(=C(C=C3)F)Cl)OC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ibuprofen</td>\n",
              "      <td>CC(C)CC1=CC=C(C=C1)C(C)C(=O)O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pyrazol</td>\n",
              "      <td>CC1=C(C=C(C=C1)C2=NN(C(C2)C3=CC=C(C=C3)OC)C(=S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>chlorop</td>\n",
              "      <td>CC(C)N1C2=NC=NC(=C2C(=N1)C3=CC(=C(C=C3)Cl)O)N</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-297f1b3d-c726-4e4e-abf7-8f850c281d0d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-297f1b3d-c726-4e4e-abf7-8f850c281d0d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-297f1b3d-c726-4e4e-abf7-8f850c281d0d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5dfa96ed-dbdb-4dd7-be11-40f15a8eae0e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5dfa96ed-dbdb-4dd7-be11-40f15a8eae0e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5dfa96ed-dbdb-4dd7-be11-40f15a8eae0e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"# NBVAL_CHECK_OUTPUT\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"ibuprofen\",\n          \"chlorop\",\n          \"Gefatinib\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"canonical_smiles\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"CC(C)CC1=CC=C(C=C1)C(C)C(=O)O\",\n          \"CC(C)N1C2=NC=NC(=C2C(=N1)C3=CC(=C(C=C3)Cl)O)N\",\n          \"COC1=C(C=C2C(=C1)N=CN=C2NC3=CC(=C(C=C3)F)Cl)OCCCN4CCOCC4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "# Load external/unlabeled data set\n",
        "external_data = pd.read_csv(\"/content/sample_data/test.csv\", index_col=0)\n",
        "external_data = external_data.reset_index(drop=True)\n",
        "external_data.head()\n",
        "# NBVAL_CHECK_OUTPUT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQhAOIVnts3E"
      },
      "source": [
        "We use the same `smiles_to_fp` function and convert the SMILES strings into MACCS fingerprints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "tags": [],
        "id": "vaUSoa8gts3E",
        "outputId": "c0c1631d-efc0-449c-d1e2-992467dc448a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of dataframe :  (4, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Unnamed: 1                                   canonical_smiles  \\\n",
              "0  Gefatinib  COC1=C(C=C2C(=C1)N=CN=C2NC3=CC(=C(C=C3)F)Cl)OC...   \n",
              "1  ibuprofen                      CC(C)CC1=CC=C(C=C1)C(C)C(=O)O   \n",
              "2    pyrazol  CC1=C(C=C(C=C1)C2=NN(C(C2)C3=CC=C(C=C3)OC)C(=S...   \n",
              "\n",
              "                                     fingerprints_df  \n",
              "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4528c7bd-6fb3-4c4c-8c84-4fb7c747a1d4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 1</th>\n",
              "      <th>canonical_smiles</th>\n",
              "      <th>fingerprints_df</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Gefatinib</td>\n",
              "      <td>COC1=C(C=C2C(=C1)N=CN=C2NC3=CC(=C(C=C3)F)Cl)OC...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ibuprofen</td>\n",
              "      <td>CC(C)CC1=CC=C(C=C1)C(C)C(=O)O</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pyrazol</td>\n",
              "      <td>CC1=C(C=C(C=C1)C2=NN(C(C2)C3=CC=C(C=C3)OC)C(=S...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4528c7bd-6fb3-4c4c-8c84-4fb7c747a1d4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4528c7bd-6fb3-4c4c-8c84-4fb7c747a1d4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4528c7bd-6fb3-4c4c-8c84-4fb7c747a1d4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-23208852-7fa9-4b5f-9de2-a53e51316ead\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-23208852-7fa9-4b5f-9de2-a53e51316ead')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-23208852-7fa9-4b5f-9de2-a53e51316ead button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"# NBVAL_CHECK_OUTPUT\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Gefatinib\",\n          \"ibuprofen\",\n          \"pyrazol\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"canonical_smiles\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"COC1=C(C=C2C(=C1)N=CN=C2NC3=CC(=C(C=C3)F)Cl)OCCCN4CCOCC4\",\n          \"CC(C)CC1=CC=C(C=C1)C(C)C(=O)O\",\n          \"CC1=C(C=C(C=C1)C2=NN(C(C2)C3=CC=C(C=C3)OC)C(=S)N)C\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fingerprints_df\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "# Convert SMILES strings to MACCS fingerprints\n",
        "external_data[\"fingerprints_df\"] = external_data[\"canonical_smiles\"].apply(smiles_to_fp)\n",
        "\n",
        "# Look at head\n",
        "print(\"Shape of dataframe : \", external_data.shape)\n",
        "external_data.head(3)\n",
        "# NBVAL_CHECK_OUTPUT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IcW-iNOts3E"
      },
      "source": [
        "**Note**: For reproducibility of the results, we saved one model under `ANN_model.hdf5`, with the same architecture as above. Even though the model is the same, the weights that are saved from one simulation to another might differ due to the randomness in the _stochastic_ gradient algorithm. We load the ANN model weights with the [load_model()](https://keras.io/api/models/model_saving_apis/#loadmodel-function) function."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load json and create model\n",
        "json_file = open(\"model.json\", \"r\")\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"model.weights.h5\")\n",
        "print(\"Loaded model from disk\")"
      ],
      "metadata": {
        "id": "R4fH8WWCfwsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "03sdGmRAts3E"
      },
      "outputs": [],
      "source": [
        "# Load model\n",
        "model = load_model(\"/content/model.weights.h5\", compile=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "4aZGXC9xts3E"
      },
      "outputs": [],
      "source": [
        "# Prediction on external/unlabeled data\n",
        "predictions = model.predict(\n",
        "    np.array(list((external_data[\"fingerprints_df\"]))).astype(float), callbacks=callbacks_list\n",
        ")\n",
        "\n",
        "predicted_pIC50 = pd.DataFrame(predictions, columns=[\"predicted_pIC50\"])\n",
        "predicted_pIC50_df = external_data.join(predicted_pIC50)\n",
        "\n",
        "predicted_pIC50_df.head(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "tags": [],
        "id": "DI3cel9vts3F"
      },
      "outputs": [],
      "source": [
        "# Save the predicted values in a csv file in the data folder\n",
        "predicted_pIC50_df.to_csv(\"/content/sample_data/predicted_pIC50_df.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbiv0jREts3F"
      },
      "source": [
        "#### Select the top 3 compounds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gdVTlRTts3F"
      },
      "source": [
        "We select the 3 compounds with the highest predicted pIC50 values, which could be further investigated as potential EGRF inhibitors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "Cad81506ts3F"
      },
      "outputs": [],
      "source": [
        "# Select top 3 drugs\n",
        "predicted_pIC50_df = pd.read_csv(\"/content/sample_data/predicted_pIC50_df.csv\", index_col=0)\n",
        "top3_drug = predicted_pIC50_df.nlargest(3, \"predicted_pIC50\")\n",
        "top3_drug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "DpSVhxRSts3F"
      },
      "outputs": [],
      "source": [
        "# Draw the drug molecules\n",
        "highest_pIC50 = predicted_pIC50_df[\"canonical_smiles\"][top3_drug.index]\n",
        "\n",
        "mols_EGFR = [Chem.MolFromSmiles(smile) for smile in highest_pIC50]\n",
        "pIC50_EGFR = top3_drug[\"predicted_pIC50\"].tolist()\n",
        "pIC50_values = [(f\"pIC50 value: {value:.2f}\") for value in pIC50_EGFR]\n",
        "\n",
        "Draw.MolsToGridImage(mols_EGFR, molsPerRow=3, subImgSize=(450, 300), legends=pIC50_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-fjKxcSts3F"
      },
      "source": [
        "## Discussion\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtXm_mc2ts3F"
      },
      "source": [
        "After seeing the molecular structures, you will be able to observe some similarities. Here we have used just random few test molecules, therefore you can expect similarity above.\n",
        "It also means that now constructing a library of unknown compounds is a real task now :-), on a light note."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "toc-autonumbering": true,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}